{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3954389,"sourceType":"datasetVersion","datasetId":2346873}],"dockerImageVersionId":30512,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **URDU-ENGLISH TRANSLATION USING CUSTOM SEQ2SEQ MODELS [WITH AND WITHOUT ATTENTION]**","metadata":{}},{"cell_type":"markdown","source":"## **IMPORT REQUIRED PACKAGES AND LIBRARIES**","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom keras.utils.vis_utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:02:24.858333Z","iopub.execute_input":"2024-02-05T18:02:24.858671Z","iopub.status.idle":"2024-02-05T18:02:40.543815Z","shell.execute_reply.started":"2024-02-05T18:02:24.858645Z","shell.execute_reply":"2024-02-05T18:02:40.542971Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **IMPORT REQUIRED DATASET**","metadata":{}},{"cell_type":"code","source":"ds=pd.read_csv(\"/kaggle/input/bible-dataset-with-english-to-urdu-translation/bible.csv\",names=['English','Urdu'])","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:03:00.529307Z","iopub.execute_input":"2024-02-05T18:03:00.530541Z","iopub.status.idle":"2024-02-05T18:03:00.641460Z","shell.execute_reply.started":"2024-02-05T18:03:00.530505Z","shell.execute_reply":"2024-02-05T18:03:00.640673Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"ds.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:03:20.097096Z","iopub.execute_input":"2024-02-05T18:03:20.097494Z","iopub.status.idle":"2024-02-05T18:03:20.112328Z","shell.execute_reply.started":"2024-02-05T18:03:20.097458Z","shell.execute_reply":"2024-02-05T18:03:20.111154Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                             English  \\\n0  The book of the generation of Jesus Christ , t...   \n1  Abraham begat Isaac ; and Isaac begat Jacob ; ...   \n2  And Judas begat Phares and Zara of Thamar ; an...   \n3  And Aram begat Aminadab ; and Aminadab begat N...   \n4  And Salmon begat Booz of Rachab ; and Booz beg...   \n\n                                                Urdu  \n0         یسُوع مسیح ابن داود ابن ابرہام کا نسب نامہ  \n1  ابراہام سے اِضحاق پیدا ہُوا اور اِضحاق سے یعقو...  \n2  اور یہوداہ سے فارص اور زارح تمر سے پیدا ہوئے ا...  \n3  اور رام سے عمینداب پیدا ہُوا اور عمینداب سے نح...  \n4  اور سلمون سے بوعز راحب سے پیدا ہُوا اور بوعز س...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Urdu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The book of the generation of Jesus Christ , t...</td>\n      <td>یسُوع مسیح ابن داود ابن ابرہام کا نسب نامہ</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Abraham begat Isaac ; and Isaac begat Jacob ; ...</td>\n      <td>ابراہام سے اِضحاق پیدا ہُوا اور اِضحاق سے یعقو...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>And Judas begat Phares and Zara of Thamar ; an...</td>\n      <td>اور یہوداہ سے فارص اور زارح تمر سے پیدا ہوئے ا...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>And Aram begat Aminadab ; and Aminadab begat N...</td>\n      <td>اور رام سے عمینداب پیدا ہُوا اور عمینداب سے نح...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>And Salmon begat Booz of Rachab ; and Booz beg...</td>\n      <td>اور سلمون سے بوعز راحب سے پیدا ہُوا اور بوعز س...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## **DATA PREPROCESSING**","metadata":{}},{"cell_type":"code","source":"ds=ds.dropna()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:03:23.479115Z","iopub.execute_input":"2024-02-05T18:03:23.479460Z","iopub.status.idle":"2024-02-05T18:03:23.496412Z","shell.execute_reply.started":"2024-02-05T18:03:23.479419Z","shell.execute_reply":"2024-02-05T18:03:23.495355Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import re\ndef preprocess_sentence(s):\n  s=s.lower()\n  s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n  s = re.sub(r'[\" \"]+', \" \", s)\n  s = s.strip()\n  return s","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:03:31.365531Z","iopub.execute_input":"2024-02-05T18:03:31.365930Z","iopub.status.idle":"2024-02-05T18:03:31.371326Z","shell.execute_reply.started":"2024-02-05T18:03:31.365899Z","shell.execute_reply":"2024-02-05T18:03:31.370340Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"ds['English_clean']=ds['English'].apply(preprocess_sentence)\nds['Urdu_clean']=ds['Urdu'].apply(preprocess_sentence)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:03:37.579553Z","iopub.execute_input":"2024-02-05T18:03:37.580181Z","iopub.status.idle":"2024-02-05T18:03:37.980021Z","shell.execute_reply.started":"2024-02-05T18:03:37.580149Z","shell.execute_reply":"2024-02-05T18:03:37.979050Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/1948961939.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ds['English_clean']=ds['English'].apply(preprocess_sentence)\n/tmp/ipykernel_33/1948961939.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  ds['Urdu_clean']=ds['Urdu'].apply(preprocess_sentence)\n","output_type":"stream"}]},{"cell_type":"code","source":"def tag_target_sentences(sentences):\n  tagged_sentences = map(lambda s: (' ').join(['<sos>', s, '<eos>']), sentences)\n  return list(tagged_sentences)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:03:50.120388Z","iopub.execute_input":"2024-02-05T18:03:50.120763Z","iopub.status.idle":"2024-02-05T18:03:50.126286Z","shell.execute_reply.started":"2024-02-05T18:03:50.120733Z","shell.execute_reply":"2024-02-05T18:03:50.125232Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"input_=list(ds['English_clean'])\ntarget=tag_target_sentences(list(ds['Urdu_clean']))","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:04:00.015777Z","iopub.execute_input":"2024-02-05T18:04:00.016121Z","iopub.status.idle":"2024-02-05T18:04:00.028008Z","shell.execute_reply.started":"2024-02-05T18:04:00.016095Z","shell.execute_reply":"2024-02-05T18:04:00.026944Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## **DATA TOKENIZATION**","metadata":{}},{"cell_type":"code","source":"source_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<unk>', filters='\"#$%&()*+-/:;=@[\\\\]^_`{|}~\\t\\n')\nsource_tokenizer.fit_on_texts(input_)\nencoder_vocab=len(source_tokenizer.word_index)+1\nencoder_inputs = source_tokenizer.texts_to_sequences(input_)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:04:10.541313Z","iopub.execute_input":"2024-02-05T18:04:10.542172Z","iopub.status.idle":"2024-02-05T18:04:10.939609Z","shell.execute_reply.started":"2024-02-05T18:04:10.542140Z","shell.execute_reply":"2024-02-05T18:04:10.938693Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"target_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<unk>', filters='\"#$%&()*+-/:;=@[\\\\]^_`{|}~\\t\\n')\ntarget_tokenizer.fit_on_texts(target)\ndecoder_vocab=len(target_tokenizer.word_index)+1\nsequences = target_tokenizer.texts_to_sequences(target)\ndecoder_inputs = [s[:-1] for s in sequences] # Drop the last token in the sentence.\ndecoder_targets = [s[1:] for s in sequences] # Drop the first token in the sentence.","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:04:15.652051Z","iopub.execute_input":"2024-02-05T18:04:15.652389Z","iopub.status.idle":"2024-02-05T18:04:16.263731Z","shell.execute_reply.started":"2024-02-05T18:04:15.652362Z","shell.execute_reply":"2024-02-05T18:04:16.262944Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"target_tokenizer.sequences_to_texts(decoder_targets[0:5])","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:04:18.282017Z","iopub.execute_input":"2024-02-05T18:04:18.282354Z","iopub.status.idle":"2024-02-05T18:04:18.288859Z","shell.execute_reply.started":"2024-02-05T18:04:18.282327Z","shell.execute_reply":"2024-02-05T18:04:18.287858Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['یسُوع مسیح ابن داود ابن ابرہام کا نسب نامہ <eos>',\n 'ابراہام سے اِضحاق پیدا ہُوا اور اِضحاق سے یعقوب پیدا ہُوا اور یعقوب سے یہوداہ اور اس کے بھائی پیدا ہوئے ۔ <eos>',\n 'اور یہوداہ سے فارص اور زارح تمر سے پیدا ہوئے اور فارص سے حصرون پیدا ہُوا اور حصرون سے رام پیدا ہُوا ۔ <eos>',\n 'اور رام سے عمینداب پیدا ہُوا اور عمینداب سے نحسون پیدا ہُوا اور نحسون سے سلمون پیدا ہُوا ۔ <eos>',\n 'اور سلمون سے بوعز راحب سے پیدا ہُوا اور بوعز سے عوبید رُوت سے پیدا ہُوا اور عوبید سے یسّی پیدا ہُوا ۔ <eos>']"},"metadata":{}}]},{"cell_type":"code","source":"max_encoding_len = len(max(encoder_inputs, key=len))\nmax_decoding_len = len(max(decoder_inputs, key=len))","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:04:20.002752Z","iopub.execute_input":"2024-02-05T18:04:20.003119Z","iopub.status.idle":"2024-02-05T18:04:20.009378Z","shell.execute_reply.started":"2024-02-05T18:04:20.003089Z","shell.execute_reply":"2024-02-05T18:04:20.008396Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"padded_encoder_inputs = pad_sequences(encoder_inputs, max_encoding_len, padding='post', truncating='post')\npadded_decoder_inputs = pad_sequences(decoder_inputs, max_decoding_len, padding='post', truncating='post')\npadded_decoder_targets = pad_sequences(decoder_targets, max_decoding_len, padding='post', truncating='post')","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:04:22.084291Z","iopub.execute_input":"2024-02-05T18:04:22.084662Z","iopub.status.idle":"2024-02-05T18:04:22.224316Z","shell.execute_reply.started":"2024-02-05T18:04:22.084633Z","shell.execute_reply":"2024-02-05T18:04:22.223321Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## **CREATING MODELS**","metadata":{}},{"cell_type":"markdown","source":"### **SEQ2SEQ MODEL WITHOUT ATTENTION**","metadata":{}},{"cell_type":"code","source":"embedding_dim = 128\nhidden_dim = 256\ndefault_dropout=0.2","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:04:32.017821Z","iopub.execute_input":"2024-02-05T18:04:32.018170Z","iopub.status.idle":"2024-02-05T18:04:32.022706Z","shell.execute_reply.started":"2024-02-05T18:04:32.018143Z","shell.execute_reply":"2024-02-05T18:04:32.021813Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\nclass Encoder(layers.Layer):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout_rate=0.1):\n        super(Encoder, self).__init__(name='Encoder')\n\n        self.embedding = layers.Embedding(vocab_size, embedding_dim)\n        self.lstm = layers.LSTM(hidden_dim, return_state=True, dropout=dropout_rate)\n\n    def call(self, inputs):\n        embedding_output = self.embedding(inputs)\n        encoder_outputs, state_h, state_c = self.lstm(embedding_output)\n        encoder_states = [state_h, state_c]\n        return encoder_outputs, encoder_states\n\nclass Decoder(layers.Layer):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout_rate=0.1):\n        super(Decoder, self).__init__(name='Decoder')\n\n        self.embedding = layers.Embedding(vocab_size, embedding_dim)\n        self.lstm = layers.LSTM(hidden_dim, return_sequences=True, return_state=True, dropout=dropout_rate)\n        self.dense = layers.Dense(vocab_size, activation='softmax')\n\n    def call(self, inputs, initial_states):\n        embedding_output = self.embedding(inputs)\n        decoder_outputs, state_hh, state_cc = self.lstm(embedding_output, initial_state=initial_states)\n        decoder_states = [state_hh, state_cc]\n        logits = self.dense(decoder_outputs)\n        return logits,decoder_states\n\nclass TransformerSeq2Seq(keras.Model):\n    def __init__(self, encoder_vocab_size, decoder_vocab_size, embedding_dim, hidden_dim,encoder_tokenizer,decoder_tokenizer, dropout_rate=0.1):\n        super(TransformerSeq2Seq, self).__init__(name='Main_model_layer')\n\n        self.encoder = Encoder(encoder_vocab_size, embedding_dim, hidden_dim, dropout_rate)\n        self.decoder = Decoder(decoder_vocab_size, embedding_dim, hidden_dim, dropout_rate)\n        self.encoder_tokenizer=encoder_tokenizer\n        self.decoder_tokenizer=decoder_tokenizer\n    def call(self, inputs):\n        encoder_input, decoder_inputs = inputs\n        encoder_output, encoder_states = self.encoder(encoder_input)\n        decoder_logits,decoder_states = self.decoder(decoder_inputs, encoder_states)\n        return decoder_logits\n    \n    def predict(self,inputs):\n        encoder_input,max_decoder_len = inputs\n        encoder_input = self.encoder_tokenizer.texts_to_sequences([encoder_input])\n        max_encoding_len = len(max(encoder_input, key=len))\n        encoder_input = pad_sequences(encoder_input, maxlen=max_encoding_len, padding='post')\n        encoder_outputs, encoder_states = self.encoder(encoder_input)\n        batch_size = int(tf.shape(encoder_input)[0])\n        decoder_states = encoder_states\n        current_word = '<sos>'\n        start_token_id=self.decoder_tokenizer.word_index[current_word]\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = self.decoder_tokenizer.word_index[current_word]\n        predictions = []\n        count=10\n        for _ in range(100):\n            target_seq = np.zeros((1,1))\n            target_seq[0, 0] = self.decoder_tokenizer.word_index[current_word]\n            decoder_logits,decoder_state = self.decoder(target_seq, decoder_states)\n            decoder_states=decoder_state\n            decoder_predictions = tf.argmax(decoder_logits, axis=-1)\n            if int(decoder_predictions[0])!=0:\n                current_word = self.decoder_tokenizer.index_word[int(decoder_predictions[0])]\n                predictions.append(current_word)\n                if (current_word == '<eos>'):\n                  break\n            else:\n                current_word = self.decoder_tokenizer.index_word[1]\n                predictions.append(current_word)\n        return predictions\n\n\nmodel = TransformerSeq2Seq(encoder_vocab, decoder_vocab, embedding_dim, hidden_dim,source_tokenizer,target_tokenizer, 0.1)\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy',  metrics='sparse_categorical_accuracy')","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:04:35.563334Z","iopub.execute_input":"2024-02-05T18:04:35.563819Z","iopub.status.idle":"2024-02-05T18:04:40.713085Z","shell.execute_reply.started":"2024-02-05T18:04:35.563780Z","shell.execute_reply":"2024-02-05T18:04:40.712261Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"#### **TRAINING MODEL**","metadata":{}},{"cell_type":"code","source":"es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n\nhistory = model.fit([padded_encoder_inputs, padded_decoder_inputs], padded_decoder_targets,\n                     batch_size=16,\n                     epochs=30,\n                     callbacks=[es_callback])","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:04:54.227974Z","iopub.execute_input":"2024-02-05T18:04:54.228327Z","iopub.status.idle":"2024-02-05T18:12:33.770153Z","shell.execute_reply.started":"2024-02-05T18:04:54.228298Z","shell.execute_reply":"2024-02-05T18:12:33.769357Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/30\n498/498 [==============================] - 50s 80ms/step - loss: 2.1537 - sparse_categorical_accuracy: 0.7056\nEpoch 2/30\n498/498 [==============================] - 18s 36ms/step - loss: 1.6873 - sparse_categorical_accuracy: 0.7321\nEpoch 3/30\n498/498 [==============================] - 15s 30ms/step - loss: 1.5717 - sparse_categorical_accuracy: 0.7441\nEpoch 4/30\n498/498 [==============================] - 15s 30ms/step - loss: 1.4979 - sparse_categorical_accuracy: 0.7510\nEpoch 5/30\n498/498 [==============================] - 14s 28ms/step - loss: 1.4271 - sparse_categorical_accuracy: 0.7575\nEpoch 6/30\n498/498 [==============================] - 14s 27ms/step - loss: 1.3649 - sparse_categorical_accuracy: 0.7624\nEpoch 7/30\n498/498 [==============================] - 14s 28ms/step - loss: 1.3116 - sparse_categorical_accuracy: 0.7665\nEpoch 8/30\n498/498 [==============================] - 14s 29ms/step - loss: 1.2632 - sparse_categorical_accuracy: 0.7706\nEpoch 9/30\n498/498 [==============================] - 14s 28ms/step - loss: 1.2184 - sparse_categorical_accuracy: 0.7746\nEpoch 10/30\n498/498 [==============================] - 14s 29ms/step - loss: 1.1764 - sparse_categorical_accuracy: 0.7786\nEpoch 11/30\n498/498 [==============================] - 14s 28ms/step - loss: 1.1365 - sparse_categorical_accuracy: 0.7821\nEpoch 12/30\n498/498 [==============================] - 14s 28ms/step - loss: 1.0993 - sparse_categorical_accuracy: 0.7855\nEpoch 13/30\n498/498 [==============================] - 14s 28ms/step - loss: 1.0635 - sparse_categorical_accuracy: 0.7888\nEpoch 14/30\n498/498 [==============================] - 14s 28ms/step - loss: 1.0295 - sparse_categorical_accuracy: 0.7924\nEpoch 15/30\n498/498 [==============================] - 14s 28ms/step - loss: 0.9974 - sparse_categorical_accuracy: 0.7967\nEpoch 16/30\n498/498 [==============================] - 14s 29ms/step - loss: 0.9662 - sparse_categorical_accuracy: 0.8007\nEpoch 17/30\n498/498 [==============================] - 14s 28ms/step - loss: 0.9372 - sparse_categorical_accuracy: 0.8047\nEpoch 18/30\n498/498 [==============================] - 14s 27ms/step - loss: 0.9100 - sparse_categorical_accuracy: 0.8091\nEpoch 19/30\n498/498 [==============================] - 14s 28ms/step - loss: 0.8837 - sparse_categorical_accuracy: 0.8127\nEpoch 20/30\n498/498 [==============================] - 14s 27ms/step - loss: 0.8587 - sparse_categorical_accuracy: 0.8169\nEpoch 21/30\n498/498 [==============================] - 14s 28ms/step - loss: 0.8356 - sparse_categorical_accuracy: 0.8207\nEpoch 22/30\n498/498 [==============================] - 14s 28ms/step - loss: 0.8128 - sparse_categorical_accuracy: 0.8246\nEpoch 23/30\n498/498 [==============================] - 14s 27ms/step - loss: 0.7918 - sparse_categorical_accuracy: 0.8279\nEpoch 24/30\n498/498 [==============================] - 14s 28ms/step - loss: 0.7713 - sparse_categorical_accuracy: 0.8315\nEpoch 25/30\n498/498 [==============================] - 14s 28ms/step - loss: 0.7526 - sparse_categorical_accuracy: 0.8347\nEpoch 26/30\n498/498 [==============================] - 14s 28ms/step - loss: 0.7342 - sparse_categorical_accuracy: 0.8377\nEpoch 27/30\n498/498 [==============================] - 14s 27ms/step - loss: 0.7158 - sparse_categorical_accuracy: 0.8410\nEpoch 28/30\n498/498 [==============================] - 14s 28ms/step - loss: 0.6987 - sparse_categorical_accuracy: 0.8445\nEpoch 29/30\n498/498 [==============================] - 14s 28ms/step - loss: 0.6828 - sparse_categorical_accuracy: 0.8472\nEpoch 30/30\n498/498 [==============================] - 14s 28ms/step - loss: 0.6666 - sparse_categorical_accuracy: 0.8501\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### **MODEL INFERENCE**","metadata":{}},{"cell_type":"code","source":"model.predict([ds['English_clean'][10], max_decoding_len])","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:12:39.160259Z","iopub.execute_input":"2024-02-05T18:12:39.160983Z","iopub.status.idle":"2024-02-05T18:12:39.415031Z","shell.execute_reply.started":"2024-02-05T18:12:39.160950Z","shell.execute_reply":"2024-02-05T18:12:39.414254Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"['اور',\n 'سردار',\n 'کاہِن',\n 'اور',\n 'فقِیہ',\n 'اور',\n 'فقِیہ',\n 'اور',\n 'اُن',\n 'کے',\n 'تختے',\n 'اور',\n 'کبُوتر',\n 'فروشوں',\n 'کی',\n 'چوکیاں',\n 'اُلٹ',\n 'دِیں',\n '۔',\n '<eos>']"},"metadata":{}}]},{"cell_type":"markdown","source":"### **SEQ2SEQ MODEL WITH ATTENTION**","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\nclass Encoder(layers.Layer):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout_rate=0.1):\n        super(Encoder, self).__init__(name=\"Encoder\")\n        self.embedding = layers.Embedding(vocab_size, embedding_dim)\n        self.lstm = layers.LSTM(hidden_dim, return_state=True, dropout=dropout_rate)\n    def call(self, inputs):\n        embedding_output = self.embedding(inputs)\n        encoder_outputs, state_h, state_c = self.lstm(embedding_output)\n        encoder_states = [state_h, state_c]\n        return encoder_outputs, encoder_states\n\n\nclass LuongAttention(layers.Layer):\n  def __init__(self, hidden_dim):\n    super(LuongAttention, self).__init__()\n    self.w = layers.Dense(hidden_dim, name='encoder_outputs_dense')\n\n  def call(self, inputs):\n    encoder_output_seq, decoder_output = inputs\n    z = self.w(encoder_output_seq)  #make encoder and decoder seq_vectors of same length\n    attention_scores = tf.matmul(decoder_output, z, transpose_b=True)\n     \n    #[ [d11,d12,d13]   *   [ [e11 e21  e31]    =    [ [a11  a12 a13]\n    #  [d21,d22,d23]  *      [e12 e22 e23]     =      [a21 a22 a23]\n    # [d31,d32,d33] ] *      [e13 e32 e33] ]    =     [a31 a32 a33] ]\n    \n    attention_weights = tf.keras.activations.softmax(attention_scores, axis=-1)\n    \n    #[ [0.2,0.3,0.5]   \n    #  [0.4,0.3,0.3] \n    # [0.8,0.1,0.1] ]\n    \n    # [a1,a2,a3] *\n    context = tf.matmul(attention_weights, encoder_output_seq)\n    #[ [a11*d11 + a12*d21 + a13*d31    a21*d12 + a12*d22 + a23*d32    ]\n\n    return context\n\n\nclass Decoder(layers.Layer):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout_rate=0.1):\n        super(Decoder, self).__init__(name=\"\")\n\n        self.embedding = layers.Embedding(vocab_size, embedding_dim)\n        self.lstm = layers.LSTM(hidden_dim, return_sequences=True, return_state=True, dropout=dropout_rate)\n        self.attention = LuongAttention(hidden_dim)\n        self.w = layers.Dense(hidden_dim, activation='tanh', name='attended_outputs_dense')\n        self.dense = layers.Dense(vocab_size, activation='softmax')\n\n    def call(self,inputs):\n        input_, initial_states, encoder_outputs=inputs\n        embedding_output = self.embedding(input_)\n        decoder_outputs, state_h, state_c = self.lstm(embedding_output, initial_state=initial_states)\n        contexts = self.attention([encoder_outputs, decoder_outputs])\n        decoder_outputs= self.w(tf.concat([contexts, decoder_outputs], axis= -1))\n        logits = self.dense(decoder_outputs)\n        return logits,[state_h,state_c]\n\n\nclass TransformerSeq2Seq(keras.Model):\n    def __init__(self, encoder_vocab_size, decoder_vocab_size, embedding_dim, hidden_dim,encoder_tokenizer,decoder_tokenizer, dropout_rate=0.1):\n        super(TransformerSeq2Seq, self).__init__(name='Main_model_layer')\n\n        self.encoder = Encoder(encoder_vocab_size, embedding_dim, hidden_dim, dropout_rate)\n        self.decoder = Decoder(decoder_vocab_size, embedding_dim, hidden_dim, dropout_rate)\n        self.encoder_tokenizer=encoder_tokenizer\n        self.decoder_tokenizer=decoder_tokenizer\n\n    def call(self, inputs):\n        encoder_in, decoder_inputs = inputs\n        encoder_outputs, encoder_states = self.encoder(encoder_in)\n        decoder_logits,decoder_states = self.decoder([decoder_inputs, encoder_states, encoder_outputs])\n        return decoder_logits\n    \n    def predict(self,inputs):\n        encoder_input,max_decoder_len = inputs\n        encoder_input = self.encoder_tokenizer.texts_to_sequences([encoder_input])\n        max_encoding_len = len(max(encoder_input, key=len))\n        encoder_input = pad_sequences(encoder_input, maxlen=max_encoding_len, padding='post')\n        encoder_outputs, encoder_states = self.encoder(encoder_input)\n        decoder_states = encoder_states\n        current_word = '<sos>'\n        predictions = []\n        count=10\n        for _ in range(100):\n            target_seq = np.zeros((1,1))\n            target_seq[0, 0] = self.decoder_tokenizer.word_index[current_word]\n            decoder_logits,decoder_state = self.decoder([target_seq, decoder_states,encoder_outputs])\n            decoder_states=decoder_state\n            decoder_predictions = tf.argmax(decoder_logits, axis=-1)\n            if int(decoder_predictions[0])!=0:\n                current_word = self.decoder_tokenizer.index_word[int(decoder_predictions[0])]\n                predictions.append(current_word)\n                if (current_word == '<eos>'):\n                  break\n            else:\n                current_word = self.decoder_tokenizer.index_word[1]\n                predictions.append(current_word)\n        return predictions\n\n\nmodel1 = TransformerSeq2Seq(encoder_vocab, decoder_vocab, embedding_dim, hidden_dim,source_tokenizer,target_tokenizer, 0.1)\nmodel1.compile(optimizer='adam', loss='sparse_categorical_crossentropy',  metrics='sparse_categorical_accuracy')","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:12:51.162316Z","iopub.execute_input":"2024-02-05T18:12:51.162735Z","iopub.status.idle":"2024-02-05T18:12:51.210599Z","shell.execute_reply.started":"2024-02-05T18:12:51.162703Z","shell.execute_reply":"2024-02-05T18:12:51.209601Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"#### **MODEL TRAINING**","metadata":{}},{"cell_type":"code","source":"es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n\nhistory = model1.fit([padded_encoder_inputs, padded_decoder_inputs], padded_decoder_targets,\n                     batch_size=4,\n                     epochs=30,\n                     callbacks=[es_callback])","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:12:57.513566Z","iopub.execute_input":"2024-02-05T18:12:57.513964Z","iopub.status.idle":"2024-02-05T18:27:21.418774Z","shell.execute_reply.started":"2024-02-05T18:12:57.513929Z","shell.execute_reply":"2024-02-05T18:27:21.417678Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/30\n1989/1989 [==============================] - 55s 25ms/step - loss: 1.7774 - sparse_categorical_accuracy: 0.7306\nEpoch 2/30\n1989/1989 [==============================] - 29s 14ms/step - loss: 1.4855 - sparse_categorical_accuracy: 0.7532\nEpoch 3/30\n1989/1989 [==============================] - 29s 15ms/step - loss: 1.3547 - sparse_categorical_accuracy: 0.7639\nEpoch 4/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 1.2482 - sparse_categorical_accuracy: 0.7731\nEpoch 5/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 1.1533 - sparse_categorical_accuracy: 0.7812\nEpoch 6/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 1.0675 - sparse_categorical_accuracy: 0.7892\nEpoch 7/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.9880 - sparse_categorical_accuracy: 0.7982\nEpoch 8/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.9144 - sparse_categorical_accuracy: 0.8081\nEpoch 9/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.8480 - sparse_categorical_accuracy: 0.8181\nEpoch 10/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.7885 - sparse_categorical_accuracy: 0.8271\nEpoch 11/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.7356 - sparse_categorical_accuracy: 0.8363\nEpoch 12/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.6897 - sparse_categorical_accuracy: 0.8440\nEpoch 13/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.6473 - sparse_categorical_accuracy: 0.8519\nEpoch 14/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.6096 - sparse_categorical_accuracy: 0.8589\nEpoch 15/30\n1989/1989 [==============================] - 27s 14ms/step - loss: 0.5773 - sparse_categorical_accuracy: 0.8648\nEpoch 16/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.5470 - sparse_categorical_accuracy: 0.8709\nEpoch 17/30\n1989/1989 [==============================] - 27s 14ms/step - loss: 0.5210 - sparse_categorical_accuracy: 0.8757\nEpoch 18/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.4975 - sparse_categorical_accuracy: 0.8802\nEpoch 19/30\n1989/1989 [==============================] - 27s 14ms/step - loss: 0.4757 - sparse_categorical_accuracy: 0.8846\nEpoch 20/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.4574 - sparse_categorical_accuracy: 0.8879\nEpoch 21/30\n1989/1989 [==============================] - 27s 14ms/step - loss: 0.4396 - sparse_categorical_accuracy: 0.8919\nEpoch 22/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.4241 - sparse_categorical_accuracy: 0.8948\nEpoch 23/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.4096 - sparse_categorical_accuracy: 0.8977\nEpoch 24/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.3975 - sparse_categorical_accuracy: 0.8999\nEpoch 25/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.3858 - sparse_categorical_accuracy: 0.9024\nEpoch 26/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.3748 - sparse_categorical_accuracy: 0.9050\nEpoch 27/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.3647 - sparse_categorical_accuracy: 0.9067\nEpoch 28/30\n1989/1989 [==============================] - 27s 14ms/step - loss: 0.3568 - sparse_categorical_accuracy: 0.9079\nEpoch 29/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.3456 - sparse_categorical_accuracy: 0.9110\nEpoch 30/30\n1989/1989 [==============================] - 28s 14ms/step - loss: 0.3387 - sparse_categorical_accuracy: 0.9116\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### **MODEL INFERENCE**","metadata":{}},{"cell_type":"code","source":"model1.predict([ds['English_clean'][10], max_decoding_len])","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:27:31.941700Z","iopub.execute_input":"2024-02-05T18:27:31.942464Z","iopub.status.idle":"2024-02-05T18:27:32.263265Z","shell.execute_reply.started":"2024-02-05T18:27:31.942399Z","shell.execute_reply":"2024-02-05T18:27:32.262168Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['خُداوند',\n 'کے',\n 'نام',\n 'یعقُوب',\n 'کے',\n 'لِئے',\n 'سر',\n 'ٹھہرا',\n 'اور',\n 'اُن',\n 'کی',\n 'رُوحوں',\n 'اور',\n 'جلال',\n 'میں',\n 'بھی',\n 'رُسولوں',\n 'کے',\n 'نزدِیک',\n 'پہُنچ',\n 'گئے',\n '۔',\n '<eos>']"},"metadata":{}}]},{"cell_type":"markdown","source":"#### **SAVE MODEL**","metadata":{}},{"cell_type":"code","source":"model.save_weights(\"translation_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:27:52.793969Z","iopub.execute_input":"2024-02-05T18:27:52.794698Z","iopub.status.idle":"2024-02-05T18:27:52.873523Z","shell.execute_reply.started":"2024-02-05T18:27:52.794664Z","shell.execute_reply":"2024-02-05T18:27:52.872639Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## **CREATING INFERENCE MODEL FOR THE TRAINED MODELS (OPTIONAL)**","metadata":{}},{"cell_type":"code","source":"class InferenceTransformerSeq2Seq(keras.Model):\n    def __init__(self, encoder_vocab_size, decoder_vocab_size, embedding_dim, hidden_dim, dropout_rate,encoder_tokenizer,decoder_tokenizer):\n        super(InferenceTransformerSeq2Seq, self).__init__()\n        self.encoder = Encoder(encoder_vocab_size, embedding_dim, hidden_dim, dropout_rate)\n        self.decoder = Decoder(decoder_vocab_size, embedding_dim, hidden_dim, dropout_rate)\n        self.encoder_tokenizer=encoder_tokenizer\n        self.decoder_tokenizer=decoder_tokenizer\n\n    def call(self, inputs):\n        encoder_input,max_decoder_len = inputs\n        encoder_input = self.encoder_tokenizer.texts_to_sequences(encoder_input)\n        max_encoding_len = len(max(encoder_input, key=len))\n        encoder_input = pad_sequences(encoder_input, maxlen=max_encoding_len, padding='post')\n        encoder_outputs, encoder_states = self.encoder(encoder_input)\n        decoder_states = encoder_states\n        current_word = '<sos>'\n        predictions = []\n        count=10\n        for _ in range(100):\n            target_seq = np.zeros((1,1))\n            target_seq[0, 0] = self.decoder_tokenizer.word_index[current_word]\n            decoder_logits,decoder_state = self.decoder([target_seq, decoder_states,encoder_outputs])\n            decoder_states=decoder_state\n            decoder_predictions = tf.argmax(decoder_logits, axis=-1)\n            if int(decoder_predictions[0])!=0:\n                current_word = self.decoder_tokenizer.index_word[int(decoder_predictions[0])]\n                predictions.append(current_word)\n                if (current_word == '<eos>'):\n                  break\n            else:\n                current_word = self.decoder_tokenizer.index_word[1]\n                predictions.append(current_word)\n        return predictions\n","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:27:55.642783Z","iopub.execute_input":"2024-02-05T18:27:55.643126Z","iopub.status.idle":"2024-02-05T18:27:55.654027Z","shell.execute_reply.started":"2024-02-05T18:27:55.643099Z","shell.execute_reply":"2024-02-05T18:27:55.653138Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## **INFERENCE MODEL FOR SEQ2SEQ WITHOUT ATTENTION**","metadata":{}},{"cell_type":"code","source":"inference_model_without_attention = InferenceTransformerSeq2Seq(encoder_vocab, decoder_vocab, embedding_dim, hidden_dim, 0.1,source_tokenizer,target_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:27:58.984062Z","iopub.execute_input":"2024-02-05T18:27:58.984827Z","iopub.status.idle":"2024-02-05T18:27:59.006538Z","shell.execute_reply.started":"2024-02-05T18:27:58.984793Z","shell.execute_reply":"2024-02-05T18:27:59.005797Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"encoder_input = [ds['English_clean'][2]]  # Prepare your encoder inputs\n_ = inference_model_without_attention([encoder_input, 20])\n\nencoder_weights = model.get_layer('Encoder').get_weights()\ninference_model_without_attention.get_layer('Encoder').set_weights(encoder_weights)\ndecoder_weights = model.get_layer('Encoder').get_weights()\ninference_model_without_attention.get_layer('Encoder').set_weights(decoder_weights)\n\npredictions = inference_model_without_attention([encoder_input, max_decoding_len])","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:28:01.768141Z","iopub.execute_input":"2024-02-05T18:28:01.768954Z","iopub.status.idle":"2024-02-05T18:28:04.290742Z","shell.execute_reply.started":"2024-02-05T18:28:01.768922Z","shell.execute_reply":"2024-02-05T18:28:04.289935Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"\" \".join(predictions)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:28:05.959631Z","iopub.execute_input":"2024-02-05T18:28:05.959983Z","iopub.status.idle":"2024-02-05T18:28:05.966271Z","shell.execute_reply.started":"2024-02-05T18:28:05.959956Z","shell.execute_reply":"2024-02-05T18:28:05.965261Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'پکار پکار پکار یِسُور یِسُور مُتعلّق مُتعلّق مُتعلّق مُتعلّق مُتعلّق بُلا بُلا بُلا بُلا بُلا بُلا بُلا بُلا بُلا بُلا ٹل ٹل بُلا ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل ٹل'"},"metadata":{}}]},{"cell_type":"code","source":"inference_model_without_attention.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:28:07.944610Z","iopub.execute_input":"2024-02-05T18:28:07.945248Z","iopub.status.idle":"2024-02-05T18:28:07.961387Z","shell.execute_reply.started":"2024-02-05T18:28:07.945215Z","shell.execute_reply":"2024-02-05T18:28:07.960491Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Model: \"inference_transformer_seq2_seq\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Encoder (Encoder)           multiple                  1157760   \n                                                                 \n  (Decoder)                  multiple                  4098325   \n                                                                 \n=================================================================\nTotal params: 5,256,085\nTrainable params: 5,256,085\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **INFERENCE MODEL FOR SEQ2SEQ WITH ATTENTION**","metadata":{}},{"cell_type":"code","source":"inference_model_with_attention = InferenceTransformerSeq2Seq(encoder_vocab, decoder_vocab, embedding_dim, hidden_dim, 0.1,source_tokenizer,target_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:28:13.400183Z","iopub.execute_input":"2024-02-05T18:28:13.400576Z","iopub.status.idle":"2024-02-05T18:28:13.422072Z","shell.execute_reply.started":"2024-02-05T18:28:13.400545Z","shell.execute_reply":"2024-02-05T18:28:13.421163Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"encoder_input = [ds['English_clean'][2]]  # Prepare your encoder inputs\n_ = inference_model_with_attention([encoder_input, 20])\n\nencoder_weights = model1.get_layer('Encoder').get_weights()\ninference_model_with_attention.get_layer('Encoder').set_weights(encoder_weights)\ndecoder_weights = model1.get_layer('Encoder').get_weights()\ninference_model_with_attention.get_layer('Encoder').set_weights(decoder_weights)\n\npredictions = inference_model_with_attention([encoder_input, max_decoding_len])","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:28:14.974537Z","iopub.execute_input":"2024-02-05T18:28:14.974875Z","iopub.status.idle":"2024-02-05T18:28:17.527840Z","shell.execute_reply.started":"2024-02-05T18:28:14.974849Z","shell.execute_reply":"2024-02-05T18:28:17.526752Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"\" \".join(predictions)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:28:18.925275Z","iopub.execute_input":"2024-02-05T18:28:18.926243Z","iopub.status.idle":"2024-02-05T18:28:18.932759Z","shell.execute_reply.started":"2024-02-05T18:28:18.926206Z","shell.execute_reply":"2024-02-05T18:28:18.931573Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں حرفوں'"},"metadata":{}}]},{"cell_type":"code","source":"inference_model_with_attention.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T18:28:20.134370Z","iopub.execute_input":"2024-02-05T18:28:20.134752Z","iopub.status.idle":"2024-02-05T18:28:20.152373Z","shell.execute_reply.started":"2024-02-05T18:28:20.134724Z","shell.execute_reply":"2024-02-05T18:28:20.151536Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Model: \"inference_transformer_seq2_seq_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Encoder (Encoder)           multiple                  1157760   \n                                                                 \n  (Decoder)                  multiple                  4098325   \n                                                                 \n=================================================================\nTotal params: 5,256,085\nTrainable params: 5,256,085\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}